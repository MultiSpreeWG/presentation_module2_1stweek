{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import requests                  \n",
    "from bs4 import BeautifulSoup    \n",
    "import re                        \n",
    "from datetime import datetime    \n",
    "from time import mktime          \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##variables\n",
    "url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/market/get-summary\"\n",
    "token = \"22990f9b4amsh4df04e987b36e1bp18331cjsn862ed02f8065\"\n",
    "day_begin = \"01-01-1987\"\n",
    "day_end = \"01-01-2016\"\n",
    "interval = \"1d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activate the load data function\n",
    "def get_data_rollin(Stocknames, Shortnames):\n",
    "    index = 0\n",
    "    oop = {}\n",
    "    for names in Shortnames:\n",
    "        Stockname = Stocknames[index]\n",
    "        index +=1\n",
    "        oop[Stockname] = get_info(names)\n",
    "    return oop\n",
    "    \n",
    "    \n",
    "def get_info(Stock):\n",
    "    Stock = load_csv_data(Stock, interval, day_begin, day_end)\n",
    "    #if len(Stock) < 1000:\n",
    "        #Stock = load_csv_data(Stock, interval, day_begin, day_end)\n",
    "    return Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_crumbs_and_cookies(stock):\n",
    "    \n",
    "    url = 'https://finance.yahoo.com/quote/{}/history'.format(stock)\n",
    "    with requests.session():\n",
    "        header = {'Connection': 'keep-alive',\n",
    "                   'Expires': '-1',\n",
    "                   'Upgrade-Insecure-Requests': '1',\n",
    "                   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) \\\n",
    "                   AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'\n",
    "                   }\n",
    "        \n",
    "        website = requests.get(url, headers=header)\n",
    "        soup = BeautifulSoup(website.text, 'lxml')\n",
    "        crumb = re.findall('\"CrumbStore\":{\"crumb\":\"(.+?)\"}', str(soup))\n",
    "\n",
    "        return (header, crumb[0], website.cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix(date):\n",
    "    \n",
    "    datum = datetime.strptime(date, '%d-%m-%Y')\n",
    "    \n",
    "    return int(mktime(datum.timetuple()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(stock, interval, day_begin, day_end):\n",
    "  \n",
    "    day_begin_unix = convert_to_unix(day_begin)\n",
    "    day_end_unix = convert_to_unix(day_end)\n",
    "    \n",
    "    header, crumb, cookies = _get_crumbs_and_cookies(stock)\n",
    "    \n",
    "    with requests.session():\n",
    "        url = 'https://query1.finance.yahoo.com/v7/finance/download/' \\\n",
    "              '{stock}?period1={day_begin}&period2={day_end}&interval={interval}&events=history&crumb={crumb}' \\\n",
    "              .format(stock=stock, day_begin=day_begin_unix, day_end=day_end_unix, interval=interval, crumb=crumb)\n",
    "                \n",
    "        website = requests.get(url, headers=header, cookies=cookies)\n",
    "        if len(website.text) < 1000:\n",
    "            print(\"something with the data of\",stock,\"went wrong\")\n",
    "        else: print(\"mhm we've just received a shit ton of data from\",stock)\n",
    "        \n",
    "        return website.text.split('\\n')[:-1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_wrong_datasets(List_of_raws, compname):\n",
    "    index = 0 \n",
    "    companynames = list()\n",
    "    for x in list(List_of_raws.values()):\n",
    "        if len(List_of_raws[compname[index]]) < 500:\n",
    "            #print(len(List_of_raws[compname[index]]))\n",
    "            del List_of_raws[compname[index]]\n",
    "            index += 1\n",
    "        else:\n",
    "            companynames.append(compname[index])\n",
    "            index += 1\n",
    "    return List_of_raws\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_comp_names(List_of_raws, compnames):\n",
    "    index = 0 \n",
    "    updated_compnames = list()\n",
    "    for x in List_of_raws:\n",
    "        if x in compnames:\n",
    "            updated_compnames.append(x)\n",
    "    return updated_compnames\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_seperated(List_of_raws, compname):\n",
    "    list2 = list()\n",
    "    compnameindex = -1\n",
    "    for x in List_of_raws.values():\n",
    "        compnameindex += 1  \n",
    "        temp = list()\n",
    "        for z in x:\n",
    "            temp.append(z.split(\",\"))\n",
    "            new_cols = [\"Date\"] \n",
    "        for name in temp[0]:\n",
    "            if name != \"Date\":\n",
    "                name = compname[compnameindex] + name\n",
    "                new_cols.append(name)\n",
    "        temp[0] = new_cols\n",
    "        list2.append(temp)\n",
    "        \n",
    "    list2 = creating_dfs(Startprocess[0], list2)\n",
    "    \n",
    "    return list2\n",
    "#df2 = pd.DataFrame(list2)\n",
    "#df2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dfs(Compnames, List):\n",
    "    df_all = pd.DataFrame(List[0])\n",
    "    df_all = df_all.rename(columns=df_all.iloc[0])\n",
    "    df_all = df_all.drop(0,axis=0)\n",
    "    index = 1 \n",
    "    while index < len(List):\n",
    "        df = pd.DataFrame(List[index]) \n",
    "        df = df.rename(columns=df.iloc[0])\n",
    "        df = df.drop(0,axis=0)\n",
    "        df_all = pd.merge(df_all,df, on=\"Date\") \n",
    "        index += 1\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START THE PROCESS\n",
    "def start():\n",
    "    Stockslist = list()\n",
    "    Stocknames = list()\n",
    "    End_of_Party = 0\n",
    "    \n",
    "    while End_of_Party == 0:\n",
    "        input_stock = (input(\"Insert the Name of the Company to add stock, otherwise enter \\\"done\\\": \"))\n",
    "        input_stock = input_stock.upper()\n",
    "        if input_stock == \"DONE\":\n",
    "            End_of_Party += 1\n",
    "        else:\n",
    "            Stocknames.append(input_stock)\n",
    "            input_stock = (input(\"Insert the SHORT NAME (Stockname) to add stock, otherwise enter \\\"done\\\": \"))\n",
    "            input_stock = input_stock.upper()\n",
    "            if input_stock == \"DONE\":\n",
    "                End_of_Party += 1\n",
    "            else:\n",
    "                Stockslist.append(input_stock)\n",
    "            continue\n",
    "        print(Stocknames)\n",
    "        print(Stockslist)\n",
    "        return Stocknames, Stockslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Startprocess = start()\n",
    "List_of_raws = get_data_rollin(Startprocess[0],Startprocess[1])\n",
    "List_of_raws = delete_wrong_datasets(List_of_raws, Startprocess[0])\n",
    "New_compnamelist = new_comp_names(List_of_raws, Startprocess[0])\n",
    "df_all = getting_data_seperated(List_of_raws, New_compnamelist)\n",
    "df_all\n",
    "\n",
    "#Software        //SAP = SAP // APPLE = AAPL // AMnAZON = AMZN // MICROSOFT = MSFT \\n\",\n",
    "#Automobil      //BMW = BMW.DE // Volkswagen = VOW3.DE // Peugeot = PEU.F // Mitsubishi = MSBHY\\n\",\n",
    "#Banks         //GOLDMAN = GS // JP MORGAN =JPM // DEUTSCHE BANK = DB // HSBC = HSBC\\n\",\n",
    "#sonst        //STARBUCKS = SBUX // WALLMART = WMT // ADIDAS = ADS.DE // NIKE = NKE\",\n",
    "#INDEX       //DOW JONES = ^DJI // DAX30 = ^GDAXI // NIKKEI = ^N225 // \n",
    "#SAP', 'APPLE', 'AMAZON', 'MICROSOFT', 'BMW', 'VOLKSWAGEN', 'PEUGOT', 'MITSUBISHI', 'GOLDMAN', 'JPMORGAN', 'DEUTSCHE', 'DB', 'HSBC']\n",
    "#['SAP', 'AAPL', 'AMZN', 'MSFT', 'BMW.DE', 'VOW3.DE', 'PEU.F', 'MSBHY', 'GS', 'JPM', 'BANK', 'HSBC']\n",
    "\n",
    "#sap sap apple aapl amazon amzn microsoft msft bmw bmw.de volkswagen vow3.de peugot peu.f mitsubishi msbhy goldman gs JPMorgan jpm DEUTSCHE.BANK DB HSBC HSBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import datetime\n",
    "test['year'] = pd.DatetimeIndex(test['Date']).year\n",
    "Indexe = Startprocess[0]\n",
    "test = test.get(test[Indexe+\"Close\"] != \"null\")\n",
    "test[Indexe+\"Close\"] = test[Indexe+\"Close\"].astype(float)\n",
    "test.reset_index(inplace=True)\n",
    "test = test.drop([Indexe+\"Open\",Indexe+\"High\",Indexe+\"Low\",Indexe+\"Adj Close\",Indexe+\"Volume\",\"Date\"],axis=1)\n",
    "test = test.groupby(\"year\").agg(np.mean)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
